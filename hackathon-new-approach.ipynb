{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import pathlib\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n",
      "\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip drive/MyDrive/hackathon_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "images_path = 'bev_classification/images'\n",
    "test_path = 'bev_classification/images/test'\n",
    "train_path = 'bev_classification/images/train'\n",
    "\n",
    "if not pathlib.Path(test_path).exists():\n",
    "    pathlib.Path(test_path).mkdir()\n",
    "\n",
    "if not pathlib.Path(train_path).exists():\n",
    "    pathlib.Path(train_path).mkdir()\n",
    "\n",
    "for file in pathlib.Path(images_path).iterdir():\n",
    "    if file.name == '.DS_Store' or \\\n",
    "        file == test_path or \\\n",
    "        file == train_path:\n",
    "        continue\n",
    "\n",
    "    if 'test' in file.name:\n",
    "        for data in pathlib.Path(file).iterdir():\n",
    "            # Only iterate over the class directories\n",
    "            if 'image-datasets' == data.name or 'input' in data.name or data.name == '.DS_Store': continue\n",
    "\n",
    "            if pathlib.Path(f'{test_path}/{data.name}').exists():\n",
    "                # print(data.name)\n",
    "                for f in pathlib.Path(data).iterdir():\n",
    "                    pathlib.Path(f).rename(f'{test_path}/{data.name}/{f.name}')\n",
    "\n",
    "            else:\n",
    "                pathlib.Path(data).rename(f'{test_path}/{data.name}')\n",
    "            # print(f'{test_path}/{data.name}')\n",
    "    else:\n",
    "        for data in pathlib.Path(file).iterdir():\n",
    "            # Only iterate over the class directories\n",
    "            if 'image-datasets' == data.name or 'input' in data.name or data.name == '.DS_Store': continue\n",
    "\n",
    "            if pathlib.Path(f'{train_path}/{data.name}').exists():\n",
    "\n",
    "                for f in pathlib.Path(data).iterdir():\n",
    "                    pathlib.Path(f).rename(f'{train_path}/{data.name}/{f.name}')\n",
    "\n",
    "            else:\n",
    "                pathlib.Path(data).rename(f'{train_path}/{data.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "train_path = 'bev_classification/images/train'\n",
    "val_path = 'bev_classification/images/val'\n",
    "\n",
    "if not pathlib.Path(val_path).exists():\n",
    "    pathlib.Path(val_path).mkdir()\n",
    "\n",
    "for id in pathlib.Path(train_path).iterdir():\n",
    "    if not pathlib.Path(f\"{val_path}/{id.name}\").exists():\n",
    "        pathlib.Path(f\"{val_path}/{id.name}\").mkdir()\n",
    "\n",
    "    files = [file for file in pathlib.Path(id).iterdir()]\n",
    "    val_files = files[:len(files)//8]\n",
    "\n",
    "    [pathlib.Path(f).rename(f'{val_path}/{id.name}/{f.name}') for f in val_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetWrapper, self).__init__()\n",
    "        self.resnet = models.resnet152(pretrained=True)\n",
    "        self.fc = Linear(2048, 99, bias=True)\n",
    "        self.set_for_finetune()\n",
    "\n",
    "    def set_for_finetune(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "\n",
    "        for l in self.resnet.conv1.parameters():\n",
    "            l.requires_grad = False\n",
    "        for l in self.resnet.bn1.parameters():\n",
    "            l.requires_grad = False\n",
    "        for layer in [self.resnet.layer1, self.resnet.layer2, self.resnet.layer3, self.resnet.layer4]:\n",
    "            for l in layer.parameters():\n",
    "                l.requires_grad = False\n",
    "        # self.resnet.layer1 #.requires_grad_ = False\n",
    "        # self.resnet.layer2.requires_grad_ = False\n",
    "        # self.resnet.layer3.requires_grad_ = False\n",
    "        # self.resnet.layer4.requires_grad_ = False\n",
    "        self.resnet.fc = self.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BevDataset(Dataset):\n",
    "  def __init__(self, root, size=224, split='train'):\n",
    "    self.split = split\n",
    "    postfix = split\n",
    "    root = os.path.join(root, 'bev_classification', 'images')\n",
    "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix) ,transform = transforms.Compose([transforms.Resize((size,size)),transforms.ToTensor()]))\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    img = self.dataset_folder[index]\n",
    "    path = self.dataset_folder.imgs[index]\n",
    "    return img[0], img[1], path[0]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# With batch_size 50, there will be 1776 iterations over the dataset per epoch\n",
    "batch_size = 10\n",
    "num_epochs = 5\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [0]\n",
    "train_accuracy = [0]\n",
    "\n",
    "val_losses = [0]\n",
    "val_accuracy = [0]\n",
    "\n",
    "model_path = 'model/mps-resnet-model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Found!\n",
      "Loading model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1 batch: 1552 accuracy: 0.00% val accuracy 0.00% loss: 0.0000 val loss: 0.0000:   4%|▍         | 1553/38865 [08:27<3:16:27,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 1 batch: 3106 accuracy: 29.44% val accuracy 57.25% loss: 3.3816 val loss: 2.1711:   8%|▊         | 3107/38865 [24:27<3:37:41,  2.74it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1106 val accuracy: 0.00% val loss: 4.3104: 100%|██████████| 1107/1107 [15:59<00:00,  1.15it/s]\n",
      "epoch: 1 batch: 4660 accuracy: 47.57% val accuracy 70.34% loss: 2.5263 val loss: 1.3940:  12%|█▏        | 4661/38865 [40:50<3:36:29,  2.63it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1106 val accuracy: 0.00% val loss: 4.9071: 100%|██████████| 1107/1107 [16:23<00:00,  1.13it/s]\n",
      "epoch: 1 batch: 6214 accuracy: 55.59% val accuracy 74.63% loss: 2.1010 val loss: 1.1023:  16%|█▌        | 6215/38865 [57:33<3:30:10,  2.59it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1106 val accuracy: 0.00% val loss: 4.5585: 100%|██████████| 1107/1107 [16:43<00:00,  1.10it/s]\n",
      "epoch: 1 batch: 7768 accuracy: 60.27% val accuracy 77.06% loss: 1.8406 val loss: 0.9586:  20%|█▉        | 7769/38865 [1:14:59<3:30:07,  2.47it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1106 val accuracy: 0.00% val loss: 5.5779: 100%|██████████| 1107/1107 [17:25<00:00,  1.06it/s]\n",
      "epoch: 1 batch: 7772 accuracy: 63.47% val accuracy 78.88% loss: 1.6634 val loss: 0.8565:  20%|██        | 7773/38865 [2:46:28<4882:38:15, 565.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2 batch: 1552 accuracy: 63.47% val accuracy 78.88% loss: 1.6634 val loss: 0.8565:  24%|██▍       | 9326/38865 [3:04:58<2:49:34,  2.90it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1106 val accuracy: 0.00% val loss: 4.8080: 100%|██████████| 1107/1107 [1:49:59<00:00,  5.96s/it]\n",
      "epoch: 2 batch: 3106 accuracy: 77.73% val accuracy 79.74% loss: 0.8672 val loss: 0.8079:  28%|██▊       | 10880/38865 [4:29:01<2:26:19,  3.19it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1106 val accuracy: 0.00% val loss: 5.1593: 100%|██████████| 1107/1107 [1:24:03<00:00,  4.56s/it]\n",
      "epoch: 2 batch: 3135 accuracy: 78.11% val accuracy 80.24% loss: 0.8464 val loss: 0.7568:  28%|██▊       | 10909/38865 [6:11:59<5:19:27,  1.46it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2 batch: 3135 accuracy: 78.11% val accuracy 80.24% loss: 0.8464 val loss: 0.7568:  28%|██▊       | 10909/38865 [6:12:00<15:53:18,  2.05s/it]\n",
      "val batch: 1106 val accuracy: 0.00% val loss: 4.8710: 100%|██████████| 1107/1107 [1:42:57<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fine_tune():\n",
    "    try:\n",
    "        gc.collect()\n",
    "        device = torch.device('mps')\n",
    "        if not pathlib.Path(model_path).exists():\n",
    "            model = ResnetWrapper().to(device)\n",
    "        else:\n",
    "            print('Model Found!')\n",
    "            print('Loading model...')\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f).to(device)\n",
    "\n",
    "        print()\n",
    "        train_loader = DataLoader(BevDataset('.'), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(BevDataset('.', split='val'), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # Only have 10 validation checks per epoch\n",
    "        val_check = len(train_loader) // 5\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        loop = tqdm(total=len(train_loader)*num_epochs, position=0)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_step_losses = []\n",
    "            train_step_accuracy = []\n",
    "            for batch, (x, y_truth, _) in enumerate(train_loader):\n",
    "                x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                y_hat = model(x)\n",
    "\n",
    "                accuracy = (y_hat.argmax(1) == y_truth).float().mean()\n",
    "                train_step_accuracy.append(accuracy.item())\n",
    "\n",
    "                loss = criterion(y_hat, y_truth)\n",
    "                train_step_losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (batch + 1) % val_check == 0:\n",
    "                    print('Validation check')\n",
    "                    val_loop = tqdm(total=len(val_loader), position=0)\n",
    "\n",
    "                    val_batch_loss = []\n",
    "                    val_batch_accuracy = []\n",
    "                    for batch, (x, y_truth, _) in enumerate(val_loader):\n",
    "                        x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        y_hat = model(x)\n",
    "\n",
    "                        accuracy = (F.softmax(y_hat,1).argmax(1) == y_truth).float().mean()\n",
    "                        val_batch_accuracy.append(accuracy.item())\n",
    "\n",
    "                        loss = criterion(y_hat, y_truth)\n",
    "                        val_batch_loss.append(loss.item())\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        val_loop.update(1)\n",
    "                        val_loop.set_description(f'val batch: {batch} val accuracy: {accuracy*100:.2f}% val loss: {loss:.4f}')\n",
    "\n",
    "                    val_losses.append(sum(val_batch_loss) / len(val_batch_loss))\n",
    "                    val_accuracy.append(sum(val_batch_accuracy) / len(val_batch_accuracy))\n",
    "\n",
    "                    train_losses.append(sum(train_step_losses) / len(train_step_losses))\n",
    "                    train_accuracy.append(sum(train_step_accuracy) / len(train_step_accuracy))\n",
    "\n",
    "                loop.update(1)\n",
    "                loop.set_description(f'epoch: {epoch+1} batch: {batch} accuracy: {train_accuracy[-1]*100:.2f}% val accuracy {val_accuracy[-1]*100:.2f}% loss: {train_losses[-1]:.4f} val loss: {val_losses[-1]:.4f}')\n",
    "\n",
    "            print('Saving model...')\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            print('Model saved.')\n",
    "    except KeyboardInterrupt:\n",
    "        print('Saving model...')\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print('Model saved.')\n",
    "\n",
    "fine_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def among_us():\n",
    "    imposter = input(\"Imposter: \")\n",
    "    amonguses = []\n",
    "    while True:\n",
    "        crewmate = input('Crewmate: ')\n",
    "        if crewmate == '':\n",
    "            break\n",
    "        amonguses.append(crewmate)\n",
    "    print('What happened? ')\n",
    "    if imposter == 'Your Mother':\n",
    "        print('Imposter wins bozo')\n",
    "    else:\n",
    "        for item in amonguses:\n",
    "            print(f\"{item} clowned on the imposter and ate part of {imposter}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
