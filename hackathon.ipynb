{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Dropout, Linear, ReLU, CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import pathlib\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BevDataset(Dataset):\n",
    "  def __init__(self, root, size=224, split='train'):\n",
    "    self.split = split\n",
    "    postfix = split\n",
    "    root = os.path.join(root, 'bev_classification', 'images')\n",
    "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix) ,transform = transforms.Compose([transforms.Resize((size,size)),transforms.ToTensor()]))\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    img = self.dataset_folder[index]\n",
    "    path = self.dataset_folder.imgs[index]\n",
    "    return img[0], img[1], path[0]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataset_folder)\n",
    "  \n",
    "# class BevTestDataset(Dataset):\n",
    "#   def __init__(self, root, size=224, split='train'):\n",
    "#     postfix = split\n",
    "#     root = os.path.join(root, 'bev_classification', 'images')\n",
    "#     self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix) ,transform = transforms.Compose([transforms.Resize((size,size)),transforms.ToTensor()]))\n",
    "\n",
    "#   def __getitem__(self,index):\n",
    "#     img = self.dataset_folder[index]\n",
    "#     path = self.dataset_folder.imgs[index]\n",
    "#     return img[0], img[1], path[0]\n",
    "  \n",
    "#   def __len__(self):\n",
    "#     return len(self.dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.2):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        output = 99\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.fc1 = Linear(512*32*32, output)\n",
    "        self.fc2 = Linear(output, output)\n",
    "        self.conv1 = Conv2d(3, 64, (3,3), padding=(1,1))\n",
    "        self.conv2 = Conv2d(64, 128, (3,3), padding=(1,1))\n",
    "        self.conv3 = Conv2d(128, 256, (3,3), padding=(1,1))\n",
    "        self.conv4 = Conv2d(256, 512, (3,3), padding=(1,1))\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # Image size = 512 x 512 x 3\n",
    "            self.conv1, \n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Image size = 256 x 256 x 64\n",
    "            self.conv2, \n",
    "            ReLU(),\n",
    "            Dropout(dropout),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Image size = 128 x 128 x 128\n",
    "            self.conv3, \n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Image size = 64 x 64 x 256\n",
    "            self.conv4,\n",
    "            ReLU(),\n",
    "            Dropout(dropout),\n",
    "            MaxPool2d(kernel_size=2, stride=2)\n",
    "            # Image size = 32 x 32 x 512\n",
    "        )\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        gain = 2**(1/2)\n",
    "        nn.init.xavier_normal_(self.fc1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.fc2.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv2.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv3.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv4.weight, gain=gain)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.net(X)\n",
    "        _, c, h, w = output.size()\n",
    "        output = output.view(-1, c*h*w)\n",
    "        output = self.dropout(self.fc1(output))\n",
    "        return self.fc2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# With batch_size 50, there will be 1776 iterations over the dataset per epoch\n",
    "num_chunks = 10\n",
    "batch_size = 5\n",
    "num_epochs = 2\n",
    "lr = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracy = []\n",
    "\n",
    "val_losses = [0]\n",
    "val_accuracy = [0]\n",
    "\n",
    "model_path = 'model/mps-model.pkl'\n",
    "\n",
    "if not pathlib.Path('model').exists():\n",
    "    pathlib.Path('model').mkdir()\n",
    "\n",
    "def train():\n",
    "    try:\n",
    "        gc.collect()\n",
    "        device = torch.device('mps')\n",
    "        if not pathlib.Path(model_path).exists():\n",
    "            model = ImageClassifier().to(device)\n",
    "        else:\n",
    "            print('Model Found!')\n",
    "            print('Loading model...')\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f).to(device)\n",
    "\n",
    "        # TODO: make sure to split the data into 10 samples and train on each \n",
    "        for i in range(num_chunks):\n",
    "            print()\n",
    "            train_loader = DataLoader(BevDataset('.', chunk=i), batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(BevDataset('.', split='val', chunk=i), batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            # Only have 10 validation checks per epoch\n",
    "            val_check = len(train_loader) // 5\n",
    "\n",
    "            criterion = CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            loop = tqdm(total=len(train_loader)*num_epochs, position=0)\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_step_losses = []\n",
    "                train_step_accuracy = []\n",
    "                for batch, (x, y_truth) in enumerate(train_loader):\n",
    "                    x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    y_hat = model(x)\n",
    "\n",
    "                    accuracy = (y_hat.argmax(1) == y_truth).float().mean()\n",
    "                    train_accuracy.append((batch*epoch, accuracy.item()))\n",
    "\n",
    "                    loss = criterion(y_hat, y_truth)\n",
    "                    train_losses.append(loss.item())\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    if (batch + 1) % val_check == 0:\n",
    "                        print('Validation check')\n",
    "                        val_loop = tqdm(total=len(val_loader), position=0)\n",
    "\n",
    "                        val_batch_loss = []\n",
    "                        val_batch_accuracy = []\n",
    "                        for batch, (x, y_truth) in enumerate(val_loader):\n",
    "                            x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            y_hat = model(x)\n",
    "\n",
    "                            accuracy = (F.softmax(y_hat,1).argmax(1) == y_truth).float().mean()\n",
    "                            val_batch_accuracy.append((batch*epoch, accuracy.item()))\n",
    "\n",
    "                            loss = criterion(y_hat, y_truth)\n",
    "                            val_batch_loss.append(loss.item())\n",
    "\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            val_loop.update(1)\n",
    "                            val_loop.set_description(f'val batch: {batch} val accuracy: {accuracy*100:.2f}% val loss: {loss:.4f}')\n",
    "\n",
    "                        val_losses.append(sum(val_batch_loss) / len(val_batch_loss))\n",
    "                        val_accuracy.append(sum(val_batch_accuracy) / len(val_batch_accuracy))\n",
    "\n",
    "                    loop.update(1)\n",
    "                    loop.set_description(f'epoch: {epoch+1} batch: {batch} accuracy: {accuracy*100:.2f}% val accuracy {val_accuracy[-1]*100:.2f}% loss: {loss:.4f} val loss: {val_losses[-1]:.4f}')\n",
    "                \n",
    "                print('Saving model...')\n",
    "                with open(model_path, 'wb') as f:\n",
    "                    pickle.dump(model, f)\n",
    "                print('Model saved.')\n",
    "    except KeyboardInterrupt:\n",
    "        print('Saving model...')\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print('Model saved.')\n",
    "\n",
    "\n",
    "# train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class VGGIntermediate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGIntermediate, self).__init__()\n",
    "        self.vgg = models.vgg19(pretrained=True)\n",
    "        self.set_up_vgg()\n",
    "\n",
    "    def set_up_vgg(self):\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_features = self.vgg.classifier[-1].in_features  # Get the number of input features for the final layer\n",
    "        self.vgg.classifier[-1] = Linear(num_features, 99)\n",
    "        # Optionally, you may want to initialize the new layer weights\n",
    "        # Initialize weights with Xavier initialization\n",
    "        torch.nn.init.xavier_uniform_(self.vgg.classifier[-1].weight)\n",
    "        # Optionally, initialize biases to zeros\n",
    "        torch.nn.init.zeros_(self.vgg.classifier[-1].bias)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.vgg(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# With batch_size 50, there will be 1776 iterations over the dataset per epoch\n",
    "batch_size = 8\n",
    "num_epochs = 2\n",
    "lr = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [0]\n",
    "train_accuracy = [0]\n",
    "\n",
    "val_losses = [0]\n",
    "val_accuracy = [0]\n",
    "\n",
    "model_path = 'model/mps-model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Found!\n",
      "Loading model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2 batch: 2204 accuracy: 0.00% val accuracy 53.15% loss: 0.0000 val loss: 8.8426:  60%|█████▉    | 13309/22208 [1:08:12<45:36,  3.25it/s]\n",
      "epoch: 1 batch: 1941 accuracy: 0.00% val accuracy 0.00% loss: 0.0000 val loss: 0.0000:  10%|▉         | 1942/19432 [07:03<1:04:13,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1580 val accuracy: 100.00% val loss: -0.0000: 100%|██████████| 1581/1581 [19:52<00:00,  1.33it/s]\n",
      "epoch: 1 batch: 3884 accuracy: 54.72% val accuracy 59.51% loss: 8.5756 val loss: 6.6549:  20%|█▉        | 3885/19432 [19:10<57:37,  4.50it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 40.00% val loss: 6.8572: 100%|██████████| 1383/1383 [12:07<00:00,  1.90it/s]\n",
      "epoch: 1 batch: 5827 accuracy: 55.36% val accuracy 60.45% loss: 8.3701 val loss: 6.3343:  30%|██▉       | 5828/19432 [32:17<59:15,  3.83it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 80.00% val loss: 4.2790: 100%|██████████| 1383/1383 [13:06<00:00,  1.76it/s]\n",
      "epoch: 1 batch: 7770 accuracy: 55.76% val accuracy 60.97% loss: 8.1723 val loss: 5.9848:  40%|███▉      | 7771/19432 [46:05<47:28,  4.09it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 60.00% val loss: 6.7955: 100%|██████████| 1383/1383 [13:47<00:00,  1.67it/s]\n",
      "epoch: 1 batch: 9713 accuracy: 56.05% val accuracy 62.45% loss: 8.0235 val loss: 5.6726:  50%|████▉     | 9714/19432 [59:32<39:22,  4.11it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 80.00% val loss: 0.9140: 100%|██████████| 1383/1383 [13:26<00:00,  1.71it/s]\n",
      "epoch: 1 batch: 9715 accuracy: 56.21% val accuracy 61.53% loss: 7.9182 val loss: 5.6270:  50%|█████     | 9716/19432 [1:05:07<190:15:20, 70.49s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2 batch: 1941 accuracy: 56.21% val accuracy 61.53% loss: 7.9182 val loss: 5.6270:  60%|█████▉    | 11658/19432 [1:13:02<31:46,  4.08it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 40.00% val loss: 5.7219: 100%|██████████| 1383/1383 [13:29<00:00,  1.71it/s]\n",
      "epoch: 2 batch: 3884 accuracy: 57.72% val accuracy 62.52% loss: 7.0769 val loss: 5.3167:  70%|██████▉   | 13601/19432 [1:46:26<21:02,  4.62it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 40.00% val loss: 9.6302: 100%|██████████| 1383/1383 [33:24<00:00,  1.45s/it]\n",
      "epoch: 2 batch: 5827 accuracy: 57.95% val accuracy 63.44% loss: 6.9603 val loss: 5.0599:  80%|███████▉  | 15544/19432 [1:58:28<14:16,  4.54it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 80.00% val loss: 0.6037: 100%|██████████| 1383/1383 [12:01<00:00,  1.92it/s]\n",
      "epoch: 2 batch: 7770 accuracy: 57.96% val accuracy 64.46% loss: 6.9337 val loss: 4.8785:  90%|████████▉ | 17487/19432 [2:10:29<07:33,  4.29it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 80.00% val loss: 1.2704: 100%|██████████| 1383/1383 [12:00<00:00,  1.92it/s]\n",
      "epoch: 2 batch: 9713 accuracy: 57.97% val accuracy 64.16% loss: 6.9000 val loss: 4.8929: 100%|█████████▉| 19430/19432 [2:22:34<00:00,  4.75it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val batch: 1382 val accuracy: 60.00% val loss: 4.2272: 100%|██████████| 1383/1383 [12:05<00:00,  1.91it/s]\n",
      "epoch: 2 batch: 9715 accuracy: 58.06% val accuracy 63.89% loss: 6.8374 val loss: 4.7125: 100%|██████████| 19432/19432 [2:27:35<00:00, 63.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saved.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 2 batch: 9715 accuracy: 58.06% val accuracy 63.89% loss: 6.8374 val loss: 4.7125: 100%|██████████| 19432/19432 [2:27:36<00:00,  2.19it/s]\n",
      "epoch: 1 batch: 60 accuracy: 58.06% val accuracy 63.89% loss: 6.8374 val loss: 4.7125:   0%|          | 61/19432 [00:13<1:08:43,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    gc.collect()\n",
    "    device = torch.device('mps')\n",
    "    if not pathlib.Path(model_path).exists():\n",
    "        model = VGGIntermediate().to(device)\n",
    "    else:\n",
    "        print('Model Found!')\n",
    "        print('Loading model...')\n",
    "        with open(model_path, 'rb') as f:\n",
    "            model = pickle.load(f).to(device)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        print()\n",
    "        train_loader = DataLoader(BevDataset('.'), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(BevDataset('.', split='val'), batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Only have 10 validation checks per epoch\n",
    "        val_check = len(train_loader) // 5\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        loop = tqdm(total=len(train_loader)*num_epochs, position=0)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_step_losses = []\n",
    "            train_step_accuracy = []\n",
    "            for batch, (x, y_truth, _) in enumerate(train_loader):\n",
    "                x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                y_hat = model(x)\n",
    "\n",
    "                accuracy = (y_hat.argmax(1) == y_truth).float().mean()\n",
    "                train_step_accuracy.append(accuracy.item())\n",
    "\n",
    "                loss = criterion(y_hat, y_truth)\n",
    "                train_step_losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (batch + 1) % val_check == 0:\n",
    "                    print('Validation check')\n",
    "                    val_loop = tqdm(total=len(val_loader), position=0)\n",
    "\n",
    "                    val_batch_loss = []\n",
    "                    val_batch_accuracy = []\n",
    "                    for batch, (x, y_truth, _) in enumerate(val_loader):\n",
    "                        x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        y_hat = model(x)\n",
    "\n",
    "                        accuracy = (F.softmax(y_hat,1).argmax(1) == y_truth).float().mean()\n",
    "                        val_batch_accuracy.append(accuracy.item())\n",
    "\n",
    "                        loss = criterion(y_hat, y_truth)\n",
    "                        val_batch_loss.append(loss.item())\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        val_loop.update(1)\n",
    "                        val_loop.set_description(f'val batch: {batch} val accuracy: {accuracy*100:.2f}% val loss: {loss:.4f}')\n",
    "\n",
    "                    val_losses.append(sum(val_batch_loss) / len(val_batch_loss))\n",
    "                    val_accuracy.append(sum(val_batch_accuracy) / len(val_batch_accuracy))\n",
    "\n",
    "                    train_losses.append(sum(train_step_losses) / len(train_step_losses))\n",
    "                    train_accuracy.append(sum(train_step_accuracy) / len(train_step_accuracy))\n",
    "\n",
    "                loop.update(1)\n",
    "                loop.set_description(f'epoch: {epoch+1} batch: {batch} accuracy: {train_accuracy[-1]*100:.2f}% val accuracy {val_accuracy[-1]*100:.2f}% loss: {train_losses[-1]:.4f} val loss: {val_losses[-1]:.4f}')\n",
    "            \n",
    "            print('Saving model...')\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            print('Model saved.')\n",
    "except KeyboardInterrupt:\n",
    "    print('Saving model...')\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
