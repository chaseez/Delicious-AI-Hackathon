{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, Dropout, Linear, ReLU, CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "import pathlib\n",
    "import pickle\n",
    "import torch\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BevDataset(Dataset):\n",
    "  def __init__(self, root, size=224, split='train'):\n",
    "    self.split = split\n",
    "    postfix = split\n",
    "    root = os.path.join(root, 'bev_classification', 'images')\n",
    "    self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix) ,transform = transforms.Compose([transforms.Resize((size,size)),transforms.ToTensor()]))\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    img = self.dataset_folder[index]\n",
    "    path = self.dataset_folder.imgs[index]\n",
    "    return img[0], img[1], path[0]\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataset_folder)\n",
    "  \n",
    "# class BevTestDataset(Dataset):\n",
    "#   def __init__(self, root, size=224, split='train'):\n",
    "#     postfix = split\n",
    "#     root = os.path.join(root, 'bev_classification', 'images')\n",
    "#     self.dataset_folder = torchvision.datasets.ImageFolder(os.path.join(root, postfix) ,transform = transforms.Compose([transforms.Resize((size,size)),transforms.ToTensor()]))\n",
    "\n",
    "#   def __getitem__(self,index):\n",
    "#     img = self.dataset_folder[index]\n",
    "#     path = self.dataset_folder.imgs[index]\n",
    "#     return img[0], img[1], path[0]\n",
    "  \n",
    "#   def __len__(self):\n",
    "#     return len(self.dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.2):\n",
    "        super(ImageClassifier, self).__init__()\n",
    "        output = 99\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.fc1 = Linear(512*32*32, output)\n",
    "        self.fc2 = Linear(output, output)\n",
    "        self.conv1 = Conv2d(3, 64, (3,3), padding=(1,1))\n",
    "        self.conv2 = Conv2d(64, 128, (3,3), padding=(1,1))\n",
    "        self.conv3 = Conv2d(128, 256, (3,3), padding=(1,1))\n",
    "        self.conv4 = Conv2d(256, 512, (3,3), padding=(1,1))\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # Image size = 512 x 512 x 3\n",
    "            self.conv1, \n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Image size = 256 x 256 x 64\n",
    "            self.conv2, \n",
    "            ReLU(),\n",
    "            Dropout(dropout),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Image size = 128 x 128 x 128\n",
    "            self.conv3, \n",
    "            ReLU(),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            # Image size = 64 x 64 x 256\n",
    "            self.conv4,\n",
    "            ReLU(),\n",
    "            Dropout(dropout),\n",
    "            MaxPool2d(kernel_size=2, stride=2)\n",
    "            # Image size = 32 x 32 x 512\n",
    "        )\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        gain = 2**(1/2)\n",
    "        nn.init.xavier_normal_(self.fc1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.fc2.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv1.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv2.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv3.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.conv4.weight, gain=gain)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = self.net(X)\n",
    "        _, c, h, w = output.size()\n",
    "        output = output.view(-1, c*h*w)\n",
    "        output = self.dropout(self.fc1(output))\n",
    "        return self.fc2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# With batch_size 50, there will be 1776 iterations over the dataset per epoch\n",
    "num_chunks = 10\n",
    "batch_size = 5\n",
    "num_epochs = 2\n",
    "lr = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracy = []\n",
    "\n",
    "val_losses = [0]\n",
    "val_accuracy = [0]\n",
    "\n",
    "model_path = 'model/mps-model.pkl'\n",
    "\n",
    "if not pathlib.Path('model').exists():\n",
    "    pathlib.Path('model').mkdir()\n",
    "\n",
    "def train():\n",
    "    try:\n",
    "        gc.collect()\n",
    "        device = torch.device('mps')\n",
    "        if not pathlib.Path(model_path).exists():\n",
    "            model = ImageClassifier().to(device)\n",
    "        else:\n",
    "            print('Model Found!')\n",
    "            print('Loading model...')\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f).to(device)\n",
    "\n",
    "        # TODO: make sure to split the data into 10 samples and train on each \n",
    "        for i in range(num_chunks):\n",
    "            print()\n",
    "            train_loader = DataLoader(BevDataset('.', chunk=i), batch_size=batch_size, shuffle=True)\n",
    "            val_loader = DataLoader(BevDataset('.', split='val', chunk=i), batch_size=batch_size, shuffle=True)\n",
    "            \n",
    "            # Only have 10 validation checks per epoch\n",
    "            val_check = len(train_loader) // 5\n",
    "\n",
    "            criterion = CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            loop = tqdm(total=len(train_loader)*num_epochs, position=0)\n",
    "\n",
    "            for epoch in range(num_epochs):\n",
    "                train_step_losses = []\n",
    "                train_step_accuracy = []\n",
    "                for batch, (x, y_truth) in enumerate(train_loader):\n",
    "                    x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    y_hat = model(x)\n",
    "\n",
    "                    accuracy = (y_hat.argmax(1) == y_truth).float().mean()\n",
    "                    train_accuracy.append((batch*epoch, accuracy.item()))\n",
    "\n",
    "                    loss = criterion(y_hat, y_truth)\n",
    "                    train_losses.append(loss.item())\n",
    "\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    if (batch + 1) % val_check == 0:\n",
    "                        print('Validation check')\n",
    "                        val_loop = tqdm(total=len(val_loader), position=0)\n",
    "\n",
    "                        val_batch_loss = []\n",
    "                        val_batch_accuracy = []\n",
    "                        for batch, (x, y_truth) in enumerate(val_loader):\n",
    "                            x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            y_hat = model(x)\n",
    "\n",
    "                            accuracy = (F.softmax(y_hat,1).argmax(1) == y_truth).float().mean()\n",
    "                            val_batch_accuracy.append((batch*epoch, accuracy.item()))\n",
    "\n",
    "                            loss = criterion(y_hat, y_truth)\n",
    "                            val_batch_loss.append(loss.item())\n",
    "\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            val_loop.update(1)\n",
    "                            val_loop.set_description(f'val batch: {batch} val accuracy: {accuracy*100:.2f}% val loss: {loss:.4f}')\n",
    "\n",
    "                        val_losses.append(sum(val_batch_loss) / len(val_batch_loss))\n",
    "                        val_accuracy.append(sum(val_batch_accuracy) / len(val_batch_accuracy))\n",
    "\n",
    "                    loop.update(1)\n",
    "                    loop.set_description(f'epoch: {epoch+1} batch: {batch} accuracy: {accuracy*100:.2f}% val accuracy {val_accuracy[-1]*100:.2f}% loss: {loss:.4f} val loss: {val_losses[-1]:.4f}')\n",
    "                \n",
    "                print('Saving model...')\n",
    "                with open(model_path, 'wb') as f:\n",
    "                    pickle.dump(model, f)\n",
    "                print('Model saved.')\n",
    "    except KeyboardInterrupt:\n",
    "        print('Saving model...')\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print('Model saved.')\n",
    "\n",
    "\n",
    "# train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class VGGIntermediate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGIntermediate, self).__init__()\n",
    "        self.vgg = models.vgg19(pretrained=True)\n",
    "        self.set_up_vgg()\n",
    "\n",
    "    def set_up_vgg(self):\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        num_features = self.vgg.classifier[-1].in_features  # Get the number of input features for the final layer\n",
    "        self.vgg.classifier[-1] = Linear(num_features, 99)\n",
    "        # Optionally, you may want to initialize the new layer weights\n",
    "        # Initialize weights with Xavier initialization\n",
    "        torch.nn.init.xavier_uniform_(self.vgg.classifier[-1].weight)\n",
    "        # Optionally, initialize biases to zeros\n",
    "        torch.nn.init.zeros_(self.vgg.classifier[-1].bias)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.vgg(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# With batch_size 50, there will be 1776 iterations over the dataset per epoch\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [0]\n",
    "train_accuracy = [0]\n",
    "\n",
    "val_losses = [0]\n",
    "val_accuracy = [0]\n",
    "\n",
    "model_path = 'model/mps-model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fine_tune():\n",
    "    try:\n",
    "        gc.collect()\n",
    "        device = torch.device('mps')\n",
    "        if not pathlib.Path(model_path).exists():\n",
    "            model = VGGIntermediate().to(device)\n",
    "        else:\n",
    "            print('Model Found!')\n",
    "            print('Loading model...')\n",
    "            with open(model_path, 'rb') as f:\n",
    "                model = pickle.load(f).to(device)\n",
    "\n",
    "        print()\n",
    "        train_loader = DataLoader(BevDataset('.'), batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(BevDataset('.', split='val'), batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Only have 10 validation checks per epoch\n",
    "        val_check = len(train_loader) // 5\n",
    "\n",
    "        criterion = CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        loop = tqdm(total=len(train_loader)*num_epochs, position=0)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_step_losses = []\n",
    "            train_step_accuracy = []\n",
    "            for batch, (x, y_truth, _) in enumerate(train_loader):\n",
    "                x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                y_hat = model(x)\n",
    "\n",
    "                accuracy = (y_hat.argmax(1) == y_truth).float().mean()\n",
    "                train_step_accuracy.append(accuracy.item())\n",
    "\n",
    "                loss = criterion(y_hat, y_truth)\n",
    "                train_step_losses.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if (batch + 1) % val_check == 0:\n",
    "                    print('Validation check')\n",
    "                    val_loop = tqdm(total=len(val_loader), position=0)\n",
    "\n",
    "                    val_batch_loss = []\n",
    "                    val_batch_accuracy = []\n",
    "                    for batch, (x, y_truth, _) in enumerate(val_loader):\n",
    "                        x, y_truth = x.to(device), y_truth.to(device)\n",
    "\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        y_hat = model(x)\n",
    "\n",
    "                        accuracy = (F.softmax(y_hat,1).argmax(1) == y_truth).float().mean()\n",
    "                        val_batch_accuracy.append(accuracy.item())\n",
    "\n",
    "                        loss = criterion(y_hat, y_truth)\n",
    "                        val_batch_loss.append(loss.item())\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        val_loop.update(1)\n",
    "                        val_loop.set_description(f'val batch: {batch} val accuracy: {accuracy*100:.2f}% val loss: {loss:.4f}')\n",
    "\n",
    "                    val_losses.append(sum(val_batch_loss) / len(val_batch_loss))\n",
    "                    val_accuracy.append(sum(val_batch_accuracy) / len(val_batch_accuracy))\n",
    "\n",
    "                    train_losses.append(sum(train_step_losses) / len(train_step_losses))\n",
    "                    train_accuracy.append(sum(train_step_accuracy) / len(train_step_accuracy))\n",
    "\n",
    "                loop.update(1)\n",
    "                loop.set_description(f'epoch: {epoch+1} batch: {batch} accuracy: {train_accuracy[-1]*100:.2f}% val accuracy {val_accuracy[-1]*100:.2f}% loss: {train_losses[-1]:.4f} val loss: {val_losses[-1]:.4f}')\n",
    "            \n",
    "            print('Saving model...')\n",
    "            with open(model_path, 'wb') as f:\n",
    "                pickle.dump(model, f)\n",
    "            print('Model saved.')\n",
    "    except KeyboardInterrupt:\n",
    "        print('Saving model...')\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print('Model saved.')\n",
    "\n",
    "# fine_tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Found!\n",
      "Loading model...\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "device = torch.device('mps')\n",
    "print('Model Found!')\n",
    "print('Loading model...')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model = pickle.load(f).to(device)\n",
    "test_dataset = BevDataset('.', split='test')\n",
    "test_loader = DataLoader(BevDataset('.', split='test'), batch_size=batch_size, shuffle=True)\n",
    "test_classes = test_dataset.dataset_folder.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(y_hat, paths, f):\n",
    "    class_nums = F.softmax(y_hat,1).argmax(1)\n",
    "    # print(class_nums, paths)\n",
    "    class_labels = [test_classes[c] for c in class_nums]\n",
    "    # print(class_labels)\n",
    "    for path, label in zip(paths, class_labels):\n",
    "        f.write(f'{path},{label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_five_predictions(y_hat, paths, f):\n",
    "    for i in range(y_hat.size()[0]):\n",
    "        class_nums = torch.topk(y_hat[i,:].flatten(), 5).indices\n",
    "        class_labels = [str(test_classes[c]) for c in class_nums]\n",
    "        f.write(f'{paths[i]},{\",\".join(class_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1238 [01:37<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bev_classification/images/test/049000000443/075ea662-010c-4b0b-abf1-8ab84352e04a.jpg,049000000443,078000082401,049000040869,049000000450,049000004632\n",
      "./bev_classification/images/test/049000007640/8a6ee392-78c1-4f89-a2f2-dcb610fde1d1.jpg,049000007640,049000009774,012000001598,078000082401,049000024708\n",
      "./bev_classification/images/test/016571910303/68e73415-cfe8-44f7-90c9-0c9727fe432d.jpg,078000003864,611269332827,049000004632,016571910310,070847037989\n",
      "./bev_classification/images/test/016571910310/c455acc6-da2e-4c5c-9650-97a0c00a1816.jpg,016571910310,012000004520,016571910303,818094005784,858176002171\n",
      "./bev_classification/images/test/049000000443/01ba7035-339b-4f41-aeca-08d0850e4e98.jpg,049000000443,049000040869,049000050103,078000082401,049000000450\n",
      "./bev_classification/images/test/078000003864/5e2f1d0f-15b9-4d74-8ab4-8b861a84ee7d.jpg,049000024692,078000003864,049000024685,012000504051,012000171956\n",
      "./bev_classification/images/test/818094005791/f9e7a646-7ff6-40e8-957b-57167499d681.jpg,078000152166,818094005784,818094005791,611269101713,858176002058\n",
      "./bev_classification/images/test/012000004520/4839aba3-24cb-4494-92d7-1a6e12a59d15.jpg,012000004520,610764863812,611269113570,016571910310,012000171956\n"
     ]
    }
   ],
   "source": [
    "with open('test_edited.txt', 'w') as f, open('test_edited_five.txt', 'w') as f_f:\n",
    "    loop = tqdm(total=len(test_loader), position=0)\n",
    "    for x, _, path in test_loader:\n",
    "        y_hat = model(x.to(device))\n",
    "        write_predictions(y_hat, path, f)\n",
    "        write_five_predictions(y_hat, path, f_f)\n",
    "        loop.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
